
•La reconnaissance des émotions à partir des signaux audio de la langue arabe:
•L’idéee est de
transformer les signaux
audio aux spectogramme 
•Appliquer Deep features (resnet50) (data extraction)
•Appliquer sca (import from mealpy) for attribute selection, use this to minimise the fitness:
Pop = (n,d)
d = number of features 
Initialisation:
Ub = 1
Lb = 0
Pop = if( rand(n,D) * (1-0) * 0 > 0.5): 1 else 0
population = (np.random.rand(pop_size, num_features) > 0.5).astype(int)

Minimise fitness:
Calculate accuracy using knn.
Fitness = 0.99(1 - acc) + 0.01 * d/D
D: number of original features 
d: number of selected features 

–use k-NN for classification

-Visualisations:
Accuracy table, F score table, confusion matrix...
(If possible: Taux d'exécution (we will execute multiple times, for example after standardisation...etc))

Use this code as a start, and the same databset if it has one:
•Le code suivant applique parallel CNN avec transformer à partir
des spectrogramme afin de détecter les émotions via le lien: 

https://www.kaggle.com/code/mohammedhassanain/eaed-using-parallel-cnn-transformer
